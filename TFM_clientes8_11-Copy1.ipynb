{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c619c07f",
   "metadata": {},
   "source": [
    "# En el Notebook TFM_clientes5 creamos 2 dataframe :\n",
    "     # El primero es la base de nuestros datos ya tratados:\n",
    "           df_fecha.to_csv('data/df_tfm_base.csv',sep='|',index=False)\n",
    "        \n",
    "     # El segundo es sóló la parte de importe2 con las variables de importe de meses anteriores por cliente\n",
    "         df_cl_tot.to_csv('data/df_cl_tot.csv',sep='|',index=False)\n",
    "\n",
    "# En el Notebook TFM_clientes6 Creamos un autoarima para los clientes estacionales, donde predecimos 12 meses por cliente\n",
    "       # Exportamos los estacionales y no estacionales para trabajarlos aparte y buscar clusters\n",
    "            df_SI_est.to_csv('data/df_SI_est.csv',sep='|',index=False)\n",
    "            df_NO_est.to_csv('data/df_NO_est.csv',sep='|',index=False)\n",
    "   \n",
    "       # Fichero total diferenciando estacionalida yno estacionalidad\n",
    "          df_est_total.to_csv('data/df_est_total.csv',sep='|',index=False)\n",
    "       \n",
    "       # Exportamos las predicciones\n",
    "            df_tot_exito0.to_csv('data/Prediccion.csv',sep='|',index=False)\n",
    "       \n",
    "\n",
    "# Vamos ahora a repetir el ejercicio pero prediciendo los 2 meses siguientes, aunque nos quedemos con el segundo, y repitendo mes a mes\n",
    "\n",
    "# En el progrma clientes8_1 y 8_2 pero desglosamos el 7 en 2 veces porque excede de memoria: hasta el cliente 4000 y a partir del 4000\n",
    "\n",
    "# Repetimos para NO ESTACIONALES\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f739122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import statsmodels.graphics.tsaplots as sgt \n",
    "import statsmodels.tsa.stattools as sts \n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from scipy.stats.distributions import chi2\n",
    "from statsmodels.tsa.ar_model import AR,ARResults\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "from statsmodels.compat.pandas import (\n",
    "    Appender,\n",
    "    Substitution,\n",
    "    call_cached_func,\n",
    "    to_numpy,\n",
    ")\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "from numpy import log\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from random import random\n",
    "import os\n",
    "\n",
    "import pmdarima as pm\n",
    "from pmdarima.utils import tsdisplay\n",
    "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
    "from pmdarima.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c76a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperamos los fciheros anteriores de estacionalidad y no estacionalidad que son con los que vamos a trabajar\n",
    "    # ya no hace falta tener fecha como indice, pero si como columna\n",
    "\n",
    "df_NO_est=pd.read_csv('data/df_NO_est.csv',sep='|')\n",
    "\n",
    "# df_NO_est=pd.read_csv('data/df_NO_est.csv',sep='|')\n",
    "# df_est_total=pd.read_csv('data/df_est_total.csv',sep='|')\n",
    "\n",
    "df_NO_est.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "import pmdarima as pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b86e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Nos quedamos con cliente, fecha e importe y llevamos la Fecha a indice\n",
    "df_fecha_si=df_NO_est.loc[:,['id_cl','Fecha','importe2']]   \n",
    "df_fecha_si.Fecha = pd.to_datetime(df_fecha_si.Fecha)\n",
    "df_fecha_si=df_fecha_si.set_index('Fecha')  # convertimos la fecha a indice\n",
    "df_fecha_si.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982181b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "696ce316",
   "metadata": {},
   "source": [
    "# modelo autoarima mes a mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cremos las funciones necesarias\n",
    "    \n",
    "    # creamos una funcion que nos calcula el valor de hace 2 meses, la diferencia y el incremento\n",
    "def create_vars(df):\n",
    "    data = df.copy()\n",
    "        \n",
    "    data['imp_2m'] = data['importe2'].shift(2)\n",
    "    data['dif_imp2']=data['importe2']-data['imp_2m']\n",
    "    data['incr_imp2']= (data['dif_imp2']/data['imp_2m']).fillna(0)\n",
    "\n",
    "  #  data['y_2m'] = data['Y'].shift(2)\n",
    "  #  data['dif_y2m']=data['Y']-data['y_2m']\n",
    "  #  data['incr_y2']= (data['dif_y2m']/data['y_2m']).fillna(0)\n",
    "    \n",
    "    data['dif_y2m']=data['Y']-data['imp_2m']\n",
    "    data['incr_y2']= (data['dif_y2m']/data['imp_2m']).fillna(0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "    # calculamos si la tendencia entre 2 meses es positiva o negativa en los datos reales y los predichos\n",
    "    # nuestro exito sera si lsa 2 tendencias son iguales\n",
    "def create_tend(df):\n",
    "    data = df.copy()\n",
    "    \n",
    "    data['tend_imp2']= np.where(data['dif_imp2']<=0, -1, 1)\n",
    "    data['tend_y2m']= np.where(data['dif_y2m']<=0, -1, 1)\n",
    "    data['exito']=np.where((data['tend_imp2']-data['tend_y2m'])==0,1,0)  \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lista_dfs_cl_tot = []\n",
    "counter = 1\n",
    "\n",
    "for cliente, df_cl_pred in list(df_fecha_si.groupby('id_cl'))[10000:14000]:\n",
    "    try:\n",
    "        print(counter)\n",
    "        counter += 1\n",
    "        X=df_cl_pred    \n",
    "\n",
    "            # creamos un indicador de periodo para trabajar mas comodamente, le pedimos uno mas porque la lista empieza por 0\n",
    "        i =list(range(37))\n",
    "        X['periodo']=i[1:]\n",
    "        \n",
    "        lista_cli12 = []\n",
    "            # creamos un rango de 12 meses que son las predicciones que vamos a hacer\n",
    "        imes=1\n",
    "        for j in range(0,11):\n",
    "            print(imes)\n",
    "            imes+=1\n",
    "                # Dejamos 2 meses para test\n",
    "            X_train = X.loc[X.periodo<=24+j]\n",
    "            y_test = X.loc[(X.periodo>(24+j)) & (X.periodo<=(24+j+2))]\n",
    "\n",
    "                # creamos el modelo con un autoarima\n",
    "            model = pm.auto_arima(X_train.importe2, start_p=1, start_q=1,\n",
    "                          test='adf',       # use adftest to find optimal 'd'\n",
    "                          max_p=4, max_q=3, # maximum p and q\n",
    "                          m=1,              # frequency of series\n",
    "                          d=None,           # let model determine 'd'\n",
    "                          seasonal=False,   # No Seasonality\n",
    "                          start_P=0, \n",
    "                          alpha=0.05,\n",
    "                          D=0, \n",
    "                          trace=True,\n",
    "                          error_action='ignore',  \n",
    "                          suppress_warnings=True, \n",
    "                          stepwise=True)\n",
    "  \n",
    "            model.fit(X_train.importe2)\n",
    "                # creamos la prediccion\n",
    "            n_periods = 2\n",
    "            fitted, confint = model.predict(n_periods=n_periods, return_conf_int=True)\n",
    "\n",
    "                # Make as pandas series\n",
    "            fitted_series = pd.Series(fitted, index=y_test.index)\n",
    "            lower_series = pd.Series(confint[:, 0], index=y_test.index)\n",
    "            upper_series = pd.Series(confint[:, 1], index=y_test.index)\n",
    "            \n",
    "            print('fitted',fitted_series)\n",
    "            \n",
    "            if lista_cli12:\n",
    "                lista_cli12.append(fitted[1])\n",
    "            else:\n",
    "                lista_cli12.append(fitted[0])\n",
    "                lista_cli12.append(fitted[1])\n",
    "            \n",
    "            \n",
    "            print('lista pred:', lista_cli12)\n",
    "            \n",
    "        # lo llevamos a un dataframe para poderlo unir a nuestro dataframe y comparar \n",
    "        # le añadimos el periodo para unir por eses campo\n",
    "        lista_cli12_b=np.array(lista_cli12)\n",
    "        data_fit=pd.DataFrame(lista_cli12_b)\n",
    "        data_fit['periodo']=i[25:]\n",
    "        print(data_fit)\n",
    "        \n",
    "            #cambiamos el nombre a la prediccion\n",
    "        data_fit=data_fit.rename({0: 'Y'}, axis=1)\n",
    "            # y unimos a los datos reales. Sólo la prediccion para comparar\n",
    "        X_fin=pd.merge(X,data_fit,left_on=['periodo'], right_on=['periodo'],how='left').loc[23:]\n",
    "\n",
    "        print(X_fin)\n",
    "            \n",
    "            # recuperamos el valor real del mes 24 para pegarselos a las predicciones y poder calcular diferencias a 2 meses# \n",
    "        #val24=X_fin.importe2[23]\n",
    "       # X_fin['Y']= X_fin['Y'].replace(np.nan,val24)\n",
    "        \n",
    "       # print(X_fin)\n",
    "\n",
    "            # Creamos variables nuevas para ver si el resultado es bueno\n",
    "        Mod_df0=create_vars(X_fin)\n",
    "            \n",
    "        print(Mod_df0)\n",
    "            \n",
    "        Mod_df=create_tend(Mod_df0).loc[24:] \n",
    "            \n",
    "        print(Mod_df)\n",
    "        lista_dfs_cl_tot.append(Mod_df)  # solo sacamos la comparativa de las predicciones\n",
    "                                          # el exito empezara a contar en el periodo 26\n",
    "    except:\n",
    "        print(counter, \"ha fallado el modelo\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_dfs_cl_tot[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_dfs_cl_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_exito0=pd.concat(lista_dfs_cl_tot)\n",
    "df_tot_exito=pd.DataFrame(df_tot_exito0.groupby('id_cl')['exito'].sum())\n",
    "df_tot_exito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot_exito=df_tot_exito.reset_index()\n",
    "n_tot_exito=df_tot_exito.groupby(['exito'])['id_cl'].count()\n",
    "n_tot_exito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75427ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unimos ambos fichero\n",
    "df_No_est_exito=pd.merge(df_tot_exito0,df_tot_exito.drop(['exito'], axis=1), left_on=['id_cl'], right_on=['id_cl'],how='left')\n",
    "df_No_est_exito.head(12)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc7eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos las predicciones\n",
    "   # v1: < 4000\\n\",\n",
    "   # v2: 4000-10000\\n\",\n",
    " # v3: 10000-14000\n",
    "df_No_est_exito.to_csv('data/Prediccion_No_est_v3.csv',sep='|',index=False)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
